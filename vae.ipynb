{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB5L6P1r/Pv8BbFo7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12cf5a898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "idx = 3\n",
    "pixels = np.reshape(mnist.train.images[idx],(28,28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "\n",
    "print(mnist.train.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs, ys = mnist.train.next_batch(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?tf.Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.py\n",
    "import tensorflow as tf\n",
    "\n",
    "class Model():\n",
    "    def __init__(self, n_input=784, n_output=10):\n",
    "        self.n_input = n_input\n",
    "        self.n_output = n_output\n",
    "        print('variational auto-encoder')\n",
    "        \n",
    "    def _build_encoder(self, input_x, layer_config=20):    \n",
    "        # variable setting\n",
    "        W_enc = tf.Variable(tf.random_normal([self.n_input, layer_config]), name='weight_enc')\n",
    "        b_enc = tf.Variable(tf.random_normal([layer_config]), name='bias_enc')\n",
    "    \n",
    "\n",
    "        # hidden layer, dim = batch_size X layer_config\n",
    "        hidden_layer = tf.matmul(input_x, W_enc) + b_enc \n",
    "        \n",
    "        \n",
    "        mean = hidden_layer[:, :self.n_output]\n",
    "        # The standard deviation must be positive. Parametrize with a softplus and\n",
    "        # add a small epsilon for numerical stability\n",
    "        stddev = 1e-6 + tf.nn.softplus(hidden_layer[:, self.n_output:])\n",
    "        return mean, stddev\n",
    "    \n",
    "    def _build_decoder(self, mean, stddev, layer_config=20):\n",
    "        \n",
    "        # reparameterization\n",
    "        eps = tf.random_normal(shape=[500, self.n_output], mean=0, stddev=1.0)\n",
    "#         mean = tf.expand_dims(mean, 1)\n",
    "#         stddev = tf.expand_dims(stddev, 1)\n",
    "        z = mean + tf.multiply(stddev, eps)\n",
    "        \n",
    "        # reconstruction\n",
    "        W_dec = tf.Variable(tf.random_normal([self.n_output, self.n_input]), name='weight_dec')\n",
    "        b_dec = tf.Variable(tf.random_normal([self.n_input]), name='bias_dec')\n",
    "    \n",
    "        output = tf.nn.sigmoid(tf.matmul(z, W_dec) + b_dec)\n",
    "        return output\n",
    "    \n",
    "    def loss(self, mean, stddev, input_x, output):\n",
    "        kl_div = 0.5 * tf.reduce_sum(tf.square(mean) + tf.square(stddev) - tf.log(1e-8 + tf.square(stddev)) - 1, 1)\n",
    "        \n",
    "        input_matrix = tf.tile(input_x, [500, 1])\n",
    "        recon_loss = tf.losses.mean_squared_error(input_matrix, output)\n",
    "\n",
    "        return recon_loss+kl_div\n",
    "    \n",
    "    def vae(self, input_x, layer_config=20):\n",
    "        mean, stddev = self._build_encoder(input_x, layer_config=layer_config)\n",
    "        output = self._build_decoder(mean=mean, stddev=stddev, layer_config=layer_config)\n",
    "        cost = self.loss(mean=mean, stddev=stddev, input_x=input_x, output=output)\n",
    "        return cost, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variational auto-encoder\n"
     ]
    }
   ],
   "source": [
    "model = Model(n_input=784, n_output=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 793.22143555]\n",
      "[ 252.9221344]\n",
      "[ 116.22473145]\n",
      "[ 728.36547852]\n",
      "[ 422.59490967]\n",
      "[ 981.70623779]\n",
      "[ 300.06384277]\n",
      "[ 735.64874268]\n",
      "[ 199.81652832]\n",
      "[ 304.18099976]\n",
      "[ 833.05023193]\n",
      "[ 220.46443176]\n",
      "[ 221.77069092]\n",
      "[ 640.08203125]\n",
      "[ 608.39086914]\n",
      "[ 421.16760254]\n",
      "[ 246.52879333]\n",
      "[ 205.95246887]\n",
      "[ 127.86470795]\n",
      "[ 597.09545898]\n",
      "[ 228.17810059]\n",
      "[ 207.65666199]\n",
      "[ 353.17089844]\n",
      "[ 241.95985413]\n",
      "[ 76.56932068]\n",
      "[ 192.01828003]\n",
      "[ 184.66157532]\n",
      "[ 319.41827393]\n",
      "[ 236.05871582]\n",
      "[ 202.53993225]\n",
      "[ 148.14337158]\n",
      "[ 187.22245789]\n",
      "[ 304.21090698]\n",
      "[ 193.61317444]\n",
      "[ 321.28485107]\n",
      "[ 196.39134216]\n",
      "[ 341.12863159]\n",
      "[ 141.67871094]\n",
      "[ 271.84838867]\n",
      "[ 287.15536499]\n",
      "[ 513.269104]\n",
      "[ 155.19831848]\n",
      "[ 261.8012085]\n",
      "[ 282.79199219]\n",
      "[ 220.83836365]\n",
      "[ 258.04415894]\n",
      "[ 78.38423157]\n",
      "[ 204.65939331]\n",
      "[ 147.23995972]\n",
      "[ 330.83218384]\n",
      "[ 121.59132385]\n",
      "[ 261.11755371]\n",
      "[ 222.9957428]\n",
      "[ 216.49000549]\n",
      "[ 125.56491089]\n",
      "[ 301.6413269]\n",
      "[ 290.82144165]\n",
      "[ 224.91046143]\n",
      "[ 358.40710449]\n",
      "[ 301.84875488]\n",
      "[ 244.65896606]\n",
      "[ 169.57452393]\n",
      "[ 274.74099731]\n",
      "[ 280.36697388]\n",
      "[ 353.64535522]\n",
      "[ 174.29826355]\n",
      "[ 357.46258545]\n",
      "[ 325.04333496]\n",
      "[ 274.4894104]\n",
      "[ 515.28900146]\n",
      "[ 277.39984131]\n",
      "[ 146.63197327]\n",
      "[ 116.34774017]\n",
      "[ 256.3578186]\n",
      "[ 237.18022156]\n",
      "[ 185.69587708]\n",
      "[ 194.96963501]\n",
      "[ 118.89742279]\n",
      "[ 118.46161652]\n",
      "[ 85.88520813]\n",
      "[ 142.04244995]\n",
      "[ 116.05886841]\n",
      "[ 372.17858887]\n",
      "[ 108.96318817]\n",
      "[ 354.72286987]\n",
      "[ 104.78772736]\n",
      "[ 147.05343628]\n",
      "[ 269.03768921]\n",
      "[ 275.72247314]\n",
      "[ 283.98480225]\n",
      "[ 231.4691925]\n",
      "[ 291.54589844]\n",
      "[ 114.58638763]\n",
      "[ 235.58178711]\n",
      "[ 131.68193054]\n",
      "[ 137.80661011]\n",
      "[ 335.92852783]\n",
      "[ 144.88343811]\n",
      "[ 117.05025482]\n",
      "[ 156.23410034]\n"
     ]
    }
   ],
   "source": [
    "# run_vae\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[1, 784])\n",
    "cost, output = model.vae(input_x=X, layer_config=20)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "\n",
    "n_batch_samples = 1\n",
    "n_epochs = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        xs, ys = mnist.train.next_batch(n_batch_samples)\n",
    "        c, op = sess.run([cost, optimizer], feed_dict={X:xs})\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batch인 경우 풀어서  w matmul, 그다음에 다시 reshape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
